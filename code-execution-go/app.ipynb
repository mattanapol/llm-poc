{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "llm_smart = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.go\n",
      "app_test.go\n",
      "go.mod\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ls'], returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\"ls\"], cwd=\"./code\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    \n",
    "class CreateFunctionPlanner:\n",
    "    def __init__(self, llm: BaseChatModel, prompt: ChatPromptTemplate):\n",
    "        self.runnable = prompt | llm\n",
    "\n",
    "    def __call__(self, state: State) -> dict:\n",
    "        return {\"messages\": [self.runnable.invoke({\"messages\": state[\"messages\"]})]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "create_function_plan_prompt = ChatPromptTemplate.from_messages([\n",
    "      (\"system\",\n",
    "      \"\"\"\n",
    "      You are professional golang developer that excel in TDD.\n",
    "      You will be provided with high level requirements.\n",
    "      Let's first understand provided requirements then create application blueprint.\n",
    "      Please create plan for implementation of functions needed to complete the requirements.\n",
    "      Each function should have a clear purpose and should be named descriptively.\n",
    "      If any function is too complex, you can break it down into smaller functions.\n",
    "      The output will be 2 parts, the first part will be the list of functions and\n",
    "      the second part will be flow of how these functions will interact with each other.\n",
    "      The first part output will start with \"Functions:\" and followed by this format,\n",
    "      - Signature:\n",
    "        Purpose:\n",
    "      The second part output will start with \"Flow:\" followed by the flow of functions.\n",
    "      After you get feedback on the plan, you will revise the plan based on the feedback.\n",
    "      No preamble or explanation is needed, just the plan.\n",
    "      \"\"\"),\n",
    "      (\"user\",\n",
    "      \"\"\"\n",
    "      {messages}\n",
    "      \"\"\"),\n",
    "  ])\n",
    "def create_function_plan(requirement: str) -> str:\n",
    "  chain = create_function_plan_prompt | llm | StrOutputParser()\n",
    "  test_cases = chain.invoke({\"input\": requirement})\n",
    "  return test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirement = \"\"\"\n",
    "Given 2 list of objects, list A and B, that each object consist of key is_main, order, and image_id.\n",
    "Return a list of change that need to be made to transform list A to list B.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "planner = CreateFunctionPlanner(llm, create_function_plan_prompt)\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"planner\", planner)\n",
    "workflow.set_entry_point(\"planner\")\n",
    "workflow.add_edge(\"planner\", END)\n",
    "\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'planner':\n",
      "---\n",
      "{'messages': [AIMessage(content='Functions:\\n- Signature: findChanges(listA []Object, listB []Object) []Change\\n  Purpose: Find and return a list of changes needed to transform list A to list B.\\n\\n- Signature: isMainChanged(objA Object, objB Object) bool\\n  Purpose: Check if the is_main attribute of two objects is different.\\n\\n- Signature: isOrderChanged(objA Object, objB Object) bool\\n  Purpose: Check if the order attribute of two objects is different.\\n\\n- Signature: isImageIDChanged(objA Object, objB Object) bool\\n  Purpose: Check if the image_id attribute of two objects is different.\\n\\n- Signature: createChange(objA Object, objB Object) Change\\n  Purpose: Create a Change object based on the differences between two objects.\\n\\n- Signature: applyChange(objA *Object, change Change)\\n  Purpose: Apply the given change to the object A.\\n\\n- Signature: revertChange(objA *Object, change Change)\\n  Purpose: Revert the given change from the object A.\\n\\nFlow:\\n1. Iterate over each object in list A and list B.\\n2. For each pair of objects, check if there are any differences in is_main, order, or image_id attributes.\\n3. If there are any differences, create a Change object.\\n4. Apply the changes to transform list A to list B.', response_metadata={'token_usage': {'completion_tokens': 279, 'prompt_tokens': 288, 'total_tokens': 567}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4dcd05e9-c47c-41e2-9a3a-c726017dc6ee-0', usage_metadata={'input_tokens': 288, 'output_tokens': 279, 'total_tokens': 567})]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "inputs = {\"messages\": [HumanMessage(content=requirement)]}\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "while True:\n",
    "    for output in app.stream(inputs, config):\n",
    "        # stream() yields dictionaries with output keyed by node name\n",
    "        for key, value in output.items():\n",
    "            print(f\"Output from node '{key}':\")\n",
    "            print(\"---\")\n",
    "            print(value)\n",
    "        print(\"\\n---\\n\")\n",
    "    snapshot = app.get_state(config)\n",
    "    # If \"next\" is present, it means we've interrupted mid-execution\n",
    "    if not snapshot.next:\n",
    "        break\n",
    "    inputs = None\n",
    "    response = input(\n",
    "        \"Do you approve the next step? Type y if you do, anything else to stop: \"\n",
    "    )\n",
    "    if response != \"y\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'planner':\n",
      "---\n",
      "{'messages': [AIMessage(content='Functions:\\n- Signature: findChanges(listA []map[string]interface{}, listB []map[string]interface{}) []map[string]interface{}\\n  Purpose: Find and return a list of changes needed to transform list A to list B.\\n\\n- Signature: areAttributesChanged(objA map[string]interface{}, objB map[string]interface{}) map[string]interface{}\\n  Purpose: Check if the attributes of two objects are different and return a map of changed attributes.\\n\\n- Signature: createChange(objA map[string]interface{}, objB map[string]interface{}) map[string]interface{}\\n  Purpose: Create a Change object based on the differences between two objects.\\n\\n- Signature: applyChange(objA *map[string]interface{}, change map[string]interface{})\\n  Purpose: Apply the given change to the object A.\\n\\n- Signature: revertChange(objA *map[string]interface{}, change map[string]interface{})\\n  Purpose: Revert the given change from the object A.\\n\\nFlow:\\n1. Iterate over each object in list A and list B.\\n2. For each pair of objects, check if there are any differences in attributes.\\n3. If there are any differences, create a Change object.\\n4. Apply the changes to transform list A to list B.', response_metadata={'token_usage': {'completion_tokens': 240, 'prompt_tokens': 1255, 'total_tokens': 1495}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c29f7f44-fa86-4b12-ad64-7985bc652d0c-0', usage_metadata={'input_tokens': 1255, 'output_tokens': 240, 'total_tokens': 1495})]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in app.stream({\"messages\": [HumanMessage(content=\"\"\"Merge all is<something>Change into one function\"\"\")]}, config):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package code\n",
      "\n",
      "func GetChanges(listA, listB []map[string]interface{}) []map[string]interface{} {\n",
      "\tvar changes []map[string]interface{}\n",
      "\n",
      "\tfor _, itemA := range listA {\n",
      "\t\tfound := false\n",
      "\t\tfor _, itemB := range listB {\n",
      "\t\t\tif itemA[\"image_id\"] == itemB[\"image_id\"] {\n",
      "\t\t\t\tfound = true\n",
      "\t\t\t\tif itemA[\"order\"] != itemB[\"order\"] || itemA[\"is_main\"] != itemB[\"is_main\"] {\n",
      "\t\t\t\t\tchange := make(map[string]interface{})\n",
      "\t\t\t\t\tchange[\"action\"] = \"update\"\n",
      "\t\t\t\t\tchange[\"id\"] = itemB[\"image_id\"]\n",
      "\t\t\t\t\tchange[\"order\"] = itemB[\"order\"]\n",
      "\t\t\t\t\tchanges = append(changes, change)\n",
      "\t\t\t\t}\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif !found {\n",
      "\t\t\tchange := make(map[string]interface{})\n",
      "\t\t\tchange[\"action\"] = \"delete\"\n",
      "\t\t\tchange[\"id\"] = itemA[\"image_id\"]\n",
      "\t\t\tchanges = append(changes, change)\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\tfor _, itemB := range listB {\n",
      "\t\tfound := false\n",
      "\t\tfor _, itemA := range listA {\n",
      "\t\t\tif itemB[\"image_id\"] == itemA[\"image_id\"] {\n",
      "\t\t\t\tfound = true\n",
      "\t\t\t\tbreak\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "\t\tif !found {\n",
      "\t\t\tchange := make(map[string]interface{})\n",
      "\t\t\tchange[\"action\"] = \"add\"\n",
      "\t\t\tchange[\"id\"] = itemB[\"image_id\"]\n",
      "\t\t\tchange[\"order\"] = itemB[\"order\"]\n",
      "\t\t\tchange[\"is_main\"] = itemB[\"is_main\"]\n",
      "\t\t\tchanges = append(changes, change)\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn changes\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_file_to_string(filename):\n",
    "  \"\"\"Reads the entire content of a file into a single string.\n",
    "\n",
    "  Args:\n",
    "      filename: The path to the file to be read.\n",
    "\n",
    "  Returns:\n",
    "      A string containing the entire content of the file, or None if the file\n",
    "      could not be opened.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    with open(filename, \"r\") as f:\n",
    "      return f.read()\n",
    "  except FileNotFoundError:\n",
    "    return None\n",
    "  \n",
    "# Example usage\n",
    "data = read_file_to_string(\"./code/app.go\")\n",
    "if data:\n",
    "  print(data)\n",
    "else:\n",
    "  print(\"File not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "def create_test_cases(requirement: str, test_cases: list[str]) -> str:\n",
    "    create_test_cases_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "        \"\"\"\n",
    "        You are professional golang developer that excel in TDD.\n",
    "        You will be provided with requirements and existing test cases.\n",
    "        Let's first understand provided requirements and create a new test case that not duplicate with existing test cases.\n",
    "        Please output a test case in json format.\n",
    "        The json will have following key: 'Name', 'Inputs' and 'Output'.\n",
    "        The test case name should be in natural language and describe the test case.\n",
    "        No preamble or explanation is needed, just the plan.\n",
    "        \"\"\"),\n",
    "        (\"user\",\n",
    "        \"\"\"\n",
    "        Requirement: {requirement}\n",
    "        Existing test cases: {test_cases}\n",
    "        \"\"\"),\n",
    "    ])\n",
    "    chain = create_test_cases_prompt | llm | JsonOutputParser()\n",
    "    test_case = chain.invoke({\"requirement\": requirement, \"test_cases\": test_cases})\n",
    "    return test_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    \"\"\"{'Name': 'A list with one object needs to be updated order to match B list', 'Inputs': {'ListA': [{'is_main': true, 'order': 1, 'image_id': 10}], 'ListB': [{'is_main': true, 'order': 2, 'image_id': 10}]}, 'Output': [{'action': 'update', 'image_id': 10, 'order': 2}]}\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'A list with one object needs to be updated order to match B list', 'Inputs': {'ListA': [{'is_main': true, 'order': 1, 'image_id': 10}], 'ListB': [{'is_main': true, 'order': 2, 'image_id': 10}]}, 'Output': [{'action': 'update', 'image_id': 10, 'order': 2}]}\n",
      "{'Name': 'A list with one object needs to be updated image_id to match B list', 'Inputs': {'ListA': [{'is_main': True, 'order': 1, 'image_id': 10}], 'ListB': [{'is_main': True, 'order': 1, 'image_id': 20}]}, 'Output': [{'action': 'update', 'image_id': 20, 'order': 1}]}\n"
     ]
    }
   ],
   "source": [
    "new_test_case = create_test_cases(requirement, test_cases)\n",
    "test_cases.append(new_test_case)\n",
    "for test_case in test_cases:\n",
    "    print(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "def create_unit_test_code(requirement: str, test_case: str, existing_code: str) -> str:\n",
    "    create_unit_test_code_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "        \"\"\"\n",
    "        You are professional golang developer that excel in TDD.\n",
    "        Let's first understand provided requirements and a test case.\n",
    "        You will be provided with a test case, expected result and existing test code that you need to modify to make it complete.\n",
    "        Please output the unit test code from the given test case and existing test code, and name the test function as 'Test<test_case_name>'.\n",
    "        No preamble or explanation is needed, just the code.\n",
    "        \"\"\"),\n",
    "        (\"user\",\n",
    "        \"\"\"\n",
    "        Requirement:\n",
    "            {requirement}\n",
    "        Test case:\n",
    "            {test_case}\n",
    "        Existing Test Code:\n",
    "        <code>\n",
    "            {existing_test_code}\n",
    "        </code>\n",
    "        \"\"\"),\n",
    "    ])\n",
    "    chain = create_unit_test_code_prompt | llm | StrOutputParser()\n",
    "    output = chain.invoke({\"requirement\": requirement,\n",
    "                            \"test_case\": test_case,\n",
    "                            \"existing_test_code\": existing_code})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```go\n",
      "package code\n",
      "\n",
      "import (\n",
      "\t\"reflect\"\n",
      "\t\"testing\"\n",
      ")\n",
      "\n",
      "func TestAListWithOneObjectNeedsToBeUpdatedImageIDToMatchBList(t *testing.T) {\n",
      "\tlistA := []map[string]interface{}{{\"is_main\": true, \"order\": 1, \"image_id\": 10}}\n",
      "\tlistB := []map[string]interface{}{{\"is_main\": true, \"order\": 1, \"image_id\": 20}}\n",
      "\texpectedOutput := []map[string]interface{}{{\"action\": \"update\", \"image_id\": 20, \"order\": 1}}\n",
      "\n",
      "\tresult := GetChanges(listA, listB)\n",
      "\n",
      "\tif !reflect.DeepEqual(result, expectedOutput) {\n",
      "\t\tt.Errorf(\"Expected %v, but got %v\", expectedOutput, result)\n",
      "\t}\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "test_case = test_cases[1]\n",
    "print(create_unit_test_code(requirement, \n",
    "                            test_case, \n",
    "                            read_file_to_string(\"./code/app_test.go\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def create_code(requirement: str, test_result: str, existing_code: str) -> str:\n",
    "    create_code_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "        \"\"\"\n",
    "        You are professional golang developer that excel in TDD.\n",
    "        Let's first understand provided requirements.\n",
    "        You will be provided with a test result, existing code that you need to modify to make it complete and pass all test cases.\n",
    "        Please output the function code.\n",
    "        No preamble or explanation is needed, just the plan.\n",
    "        \"\"\"),\n",
    "        (\"user\",\n",
    "        \"\"\"\n",
    "        Requirement:\n",
    "            {requirement}\n",
    "        Test result:\n",
    "            {test_result}\n",
    "        Code:\n",
    "        <code>\n",
    "            {code}\n",
    "        </code>\n",
    "        \"\"\"),\n",
    "    ])\n",
    "    chain = create_code_prompt | llm | StrOutputParser()\n",
    "    output = chain.invoke({\"requirement\": requirement,\n",
    "                            \"test_result\": test_result,\n",
    "                            \"code\": existing_code})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "print(create_code(requirement, \n",
    "                  test_result, \n",
    "                  read_file_to_string(\"./code/app.go\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poc-ai-code-execution-go",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
