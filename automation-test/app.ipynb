{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def call_api_get(endpoint: str, headers: dict) -> str:\n",
    "    \"\"\"\n",
    "    Make API call with GET method.\n",
    "\n",
    "    Args:\n",
    "        endpoint (str)\n",
    "        headers (dict)\n",
    "\n",
    "    Returns:\n",
    "        str: api response\n",
    "    \"\"\"\n",
    "    print(\"GET\", endpoint)\n",
    "    response = {}\n",
    "    response[\"status_code\"] = 200\n",
    "    response[\"body\"] = \"\"\"\n",
    "    {\n",
    "        \"status\": \"UP\",\n",
    "        \"error\": null,\n",
    "        \"version\": \"development\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    return str(response)\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def call_api_post(endpoint: str, body: str, headers: dict) -> str:\n",
    "    \"\"\"\n",
    "    Make API call with POST method.\n",
    "\n",
    "    Args:\n",
    "        endpoint (str)\n",
    "        body (str)\n",
    "        headers (dict)\n",
    "\n",
    "    Returns:\n",
    "        str: api response\n",
    "    \"\"\"\n",
    "    print(\"POST\", endpoint)\n",
    "    response = {}\n",
    "    response[\"status_code\"] = 500\n",
    "    response[\"body\"] = \"\"\"\n",
    "    error\n",
    "    \"\"\"\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    \"\"\"\n",
    "    Test case: Health check success\n",
    "    Endpoint: [GET] /api/v1/actuator/health\n",
    "    Expected response\n",
    "    - http status code 200\n",
    "    - response body contains\n",
    "        - \"status\": \"UP\"\n",
    "        - \"version\": \"development\"\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Test case: Dependency check success\n",
    "    Endpoint: [POST] /api/v1/dependency-check\n",
    "    Input:\n",
    "        body:```{\n",
    "            \"dependency\": \"kafka\"\n",
    "        }```\n",
    "    Expected response\n",
    "    - http status code 200\n",
    "    - response header contains\n",
    "        - \"Content-Type\": \"application/json\"\n",
    "    - response body contains\n",
    "        - \"status\": \"UP\"\n",
    "        - \"version\": \"development\"\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan:\n",
      "1. Prepare the request body with the JSON payload: `{\"dependency\": \"kafka\"}`.\n",
      "2. Send a POST request to the endpoint `/api/v1/dependency-check` with the prepared request body.\n",
      "3. Verify the HTTP status code of the response is 200.\n",
      "4. Verify the response header contains \"Content-Type\" with the value \"application/json\".\n",
      "5. Verify the response body contains the key \"status\" with the value \"UP\".\n",
      "6. Verify the response body contains the key \"version\" with the value \"development\".\n",
      "7. Report summary result of all previous steps if any failed or all passed.\n",
      "<END_OF_PLAN>\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner, planners\n",
    "from langchain.agents.tools import Tool\n",
    "\n",
    "planner_prompt = \"\"\"\n",
    "You are a developer and you need to test an API endpoint.\n",
    "You will be provide api specification, test case and expected response.\n",
    "Let's first understand provided input and create a plan to test the API.\n",
    "Please output the plan starting with the header 'Plan:' and then followed by a numbered list of steps.\n",
    "Please make the plan the minimum number of steps required to accurately complete the test.\n",
    "The final step should be 'Report summary result of all previous steps if any failed or all passed.'\n",
    "At the end of your plan, say '<END_OF_PLAN>'\n",
    "No preamble or explanation is needed, just the plan.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "agent_tools = [call_api_get,\n",
    "               call_api_post]\n",
    "\n",
    "planner = load_chat_planner(llm, system_prompt=planner_prompt)\n",
    "result = planner.llm_chain.invoke(test_cases[1])\n",
    "print(result[\"text\"])\n",
    "# executor = load_agent_executor(llm, agent_tools, verbose=True)\n",
    "\n",
    "# import uuid\n",
    "# thread_id = str(uuid.uuid4())\n",
    "\n",
    "# metadata = {\n",
    "#     \"thread_id\": thread_id\n",
    "# }\n",
    "# agent = PlanAndExecute(planner=planner, executor=executor, verbose=True, metadata=metadata)\n",
    "\n",
    "# agent.run(test_cases[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poc-ai-automation-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
