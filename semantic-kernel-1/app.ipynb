{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "service_id = \"default\"\n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(service_id=service_id, ai_model_id=\"gpt-3.5-turbo-1106\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using plugins from the samples folder\n",
    "plugins_directory = \"./plugins\"\n",
    "\n",
    "funFunctions = kernel.add_plugin(parent_directory=plugins_directory, plugin_name=\"FunPlugin\")\n",
    "\n",
    "jokeFunction = funFunctions[\"Joke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = await kernel.invoke(jokeFunction, input=\"travel to dinosaur age\", style=\"silly\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents.chat_history import ChatHistory  # noqa: F401\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments  # noqa: F401\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "from semantic_kernel.functions.kernel_function_from_prompt import KernelFunctionFromPrompt\n",
    "from semantic_kernel.core_plugins.text_plugin import TextPlugin\n",
    "import semantic_kernel as sk\n",
    "import semantic_kernel.connectors.ai.open_ai as sk_oai\n",
    "\n",
    "shakespeare_func = KernelFunctionFromPrompt(\n",
    "    function_name=\"Shakespeare\",\n",
    "    plugin_name=\"WriterPlugin\",\n",
    "    prompt=\"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the above in the style of Shakespeare.\n",
    "\"\"\",\n",
    "    prompt_execution_settings=sk_oai.OpenAIChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.8,\n",
    "    ),\n",
    "    description=\"Rewrite the input in the style of Shakespeare.\",\n",
    ")\n",
    "yoda_func = KernelFunctionFromPrompt(\n",
    "    function_name=\"Yoda\",\n",
    "    plugin_name=\"WriterPlugin\",\n",
    "    prompt=\"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the above in the style of Yoda.\n",
    "\"\"\",\n",
    "    prompt_execution_settings=sk_oai.OpenAIChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.8,\n",
    "    ),\n",
    "    description=\"Rewrite the input in the style of Yoda.\",\n",
    ")\n",
    "kernel.add_function(plugin_name=\"WriterPlugin\", function=shakespeare_func)\n",
    "kernel.add_function(plugin_name=\"WriterPlugin\", function=yoda_func)\n",
    "\n",
    "for plugin_name, plugin in kernel.plugins.items():\n",
    "    for function_name, function in plugin.functions.items():\n",
    "        print(f\"Plugin: {plugin_name}, Function: {function_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planners import SequentialPlanner\n",
    "\n",
    "ask = \"\"\"\n",
    "Tell me a joke in Shakespeare style\"\"\"\n",
    "\n",
    "planner = SequentialPlanner(kernel, service_id)\n",
    "sequential_plan = await planner.create_plan(goal=ask)\n",
    "print(\"The plan's steps are:\")\n",
    "for step in sequential_plan._steps:\n",
    "    print(\n",
    "        f\"- {step.description.replace('.', '') if step.description else 'No description'} using {step.metadata.fully_qualified_name} with parameters: {step.parameters}\"\n",
    "    )\n",
    "\n",
    "result = await sequential_plan.invoke(kernel)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "from semantic_kernel.core_plugins.math_plugin import MathPlugin\n",
    "from semantic_kernel.core_plugins.time_plugin import TimePlugin\n",
    "\n",
    "class OrderInfoPlugin:\n",
    "    \"\"\"\n",
    "    Description: OrderInfoPlugin provides a set of functions to view order information.\n",
    "    \"\"\"\n",
    "\n",
    "    @kernel_function(name=\"GetOrderList\", description=\"Given a user_id return a list of orders\")\n",
    "    def send_email(\n",
    "        self,\n",
    "        user_id: Annotated[str, \"the user id\"],\n",
    "    ) -> Annotated[list[dict], \"the list of orders\"]:\n",
    "        \"\"\"Get list of order that belong to the user\"\"\"\n",
    "        orders = [\n",
    "            {\"order_id\": \"NN-001\", \"status\": \"payment_pending\", \"price\": 100},\n",
    "            {\"order_id\": \"NN-002\", \"status\": \"in_transit\", \"price\": 50},\n",
    "        ]\n",
    "        return orders\n",
    "\n",
    "    @kernel_function(name=\"GetOrderDetail\", description=\"Given a user_id and an order_number return the order details\")\n",
    "    def get_email_address(\n",
    "        self,\n",
    "        user_id: Annotated[str, \"the user id\"],\n",
    "        order_number: Annotated[str, \"the order number\"],\n",
    "    ) -> Annotated[dict, \"the order details\"]:\n",
    "        \"\"\"Get order details\"\"\"\n",
    "        order = {\"order_id\": order_number, \n",
    "                 \"status\": \"in_transit\", \n",
    "                 \"order_placed_date\": \"2022-01-01\",\n",
    "                 \"sale_orders\": [\n",
    "                     {\"sku_number\": \"1234\", \"quantity\": 2, \"price\": 50, \"status\": \"in_transit\", \"seller_name\": \"seller_1\"},\n",
    "                     {\"sku_number\": \"1235\", \"quantity\": 2, \"price\": 50, \"status\": \"in_transit\", \"seller_name\": \"seller_2\"},\n",
    "                 ],\n",
    "                 \"price\": 100}\n",
    "        return order\n",
    "    \n",
    "kernel.add_plugin(plugin_name=\"OrderInfoPlugin\", plugin=OrderInfoPlugin())\n",
    "kernel.add_plugin(plugin_name=\"MathPlugin\", plugin=MathPlugin())\n",
    "kernel.add_plugin(plugin_name=\"TimePlugin\", plugin=TimePlugin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planners.function_calling_stepwise_planner import (\n",
    "    FunctionCallingStepwisePlanner,\n",
    "    FunctionCallingStepwisePlannerOptions,\n",
    ")\n",
    "\n",
    "question = \"Get the order list for user_id: 1234\"\n",
    "\n",
    "options = FunctionCallingStepwisePlannerOptions(\n",
    "    max_iterations=10,\n",
    "    max_tokens=4000,\n",
    ")\n",
    "\n",
    "planner = FunctionCallingStepwisePlanner(service_id=service_id, options=options)\n",
    "\n",
    "result = await planner.invoke(kernel, question)\n",
    "print(f\"Chat history: {result.chat_history}\\n\")\n",
    "print(f\"Q: {question}\\nA: {result.final_answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.open_ai_prompt_execution_settings import (\n",
    "    OpenAIChatPromptExecutionSettings,\n",
    ")\n",
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "\n",
    "prompt = \"\"\"\n",
    "{{$history}}\n",
    "User: {{$user_input}}\n",
    "ChatBot: \"\"\"\n",
    "\n",
    "execution_settings = OpenAIChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        ai_model_id=\"gpt-3.5-turbo-1106\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"chat\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"user_input\", description=\"The user input\", is_required=True),\n",
    "        InputVariable(name=\"history\", description=\"The conversation history\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=execution_settings,\n",
    ")\n",
    "\n",
    "chat_function = kernel.add_function(\n",
    "    function_name=\"chat\",\n",
    "    plugin_name=\"chatPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")\n",
    "\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_system_message(\"You are E-Commerce chatbot who can help customer about their order.\")\n",
    "\n",
    "async def chat(input_text: str) -> None:\n",
    "    # Save new message in the context variables\n",
    "    print(f\"User: {input_text}\")\n",
    "\n",
    "    # Process the user message and get an answer\n",
    "    answer = await kernel.invoke(chat_function, KernelArguments(user_input=input_text, history=chat_history))\n",
    "\n",
    "    # Show the response\n",
    "    print(f\"ChatBot: {answer}\")\n",
    "\n",
    "    chat_history.add_user_message(input_text)\n",
    "    chat_history.add_assistant_message(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat(\"My user id is 1234, get my order list?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-kernel-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
